{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Sequence, Union, Optional, Mapping\n",
    "import enum\n",
    "import logging\n",
    "\n",
    "import openai\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from openai.embeddings_utils import distances_from_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBot:\n",
    "\n",
    "    class Language(enum.Enum):\n",
    "        EN = 'en',\n",
    "        IT = 'it',\n",
    "\n",
    "    PROMPT_TEMPLATES = {\n",
    "        'en': \n",
    "            \"Answer the question based on the context below, and if the question can't be \"\n",
    "            \"answered based on the context, say \\\"I don't know.\\\"\\n\\n\"\n",
    "            \"Context: {context}\\n\\n\",\n",
    "        'it':\n",
    "            \"Rispondi alla domanda con in base al contesto sottostante e, se non è possibile \"\n",
    "            \"rispondere alla domanda in base al contesto, dì \\\"Non lo so.\\\"\\n\\n\"\n",
    "            \"Contesto: {context}\\n\\n\"\n",
    "    }\n",
    "\n",
    "    def __init__(self, \n",
    "        kb_name: str,\n",
    "        kb_language: Union[Language, str],\n",
    "        openai_api_key: str,\n",
    "        tokenizer_encoding: str = 'cl100k_base',\n",
    "        embeddings_engine: str = 'text-embedding-ada-002',\n",
    "        model_name: str = 'gpt-3.5-turbo',\n",
    "        max_prompt_len: int = 1800,\n",
    "        max_kb_article_len: int = 50,\n",
    "        max_response_len: int = 150,\n",
    "    ) -> None:\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        openai.api_key = openai_api_key\n",
    "        self.kb_name = kb_name\n",
    "        self.kb_language = str(kb_language)\n",
    "        if self.kb_language not in self.PROMPT_TEMPLATES:\n",
    "            raise ValueError(\n",
    "                f'Unsupported knowledge base langue \"{self.kb_language}\". '\n",
    "                f'Supported languages: {\", \".join(self.PROMPT_TEMPLATES.keys())}'\n",
    "            )\n",
    "        self.data_folder = Path('data') / kb_name\n",
    "        self.kb_path = self.data_folder / Path('kb.txt')\n",
    "        self.embeddings_path = self.data_folder / Path('embeddings.csv')\n",
    "        self.tokenizer = tiktoken.get_encoding(tokenizer_encoding)\n",
    "        self.embeddings_engine_name = embeddings_engine\n",
    "        self.model_name = model_name\n",
    "        self.max_prompt_len = max_prompt_len\n",
    "        self.max_kb_article_len = max_kb_article_len\n",
    "        self.max_response_len = max_response_len\n",
    "        self.history: List[Mapping[str, str]] = []\n",
    "        if self.embeddings_path.is_file():\n",
    "            self.logger.info('Embeddings file found, trying to load it ...')\n",
    "            df = pd.read_csv(self.embeddings_path)\n",
    "            df['embeddings'] = df['embeddings'].apply(eval).apply(np.array)\n",
    "            self.embeddings = df\n",
    "            self.logger.info('Embeddings were successfully loaded.')\n",
    "        else:\n",
    "            self.logger.info(\n",
    "                'Embeddings file not found, creating embeddings with OpenAI services. '\n",
    "                'This might take several minutes based on the knowledge base size ...'\n",
    "            )\n",
    "            lines = self._shortened(self.kb_path, max_tokens=self.max_kb_article_len)\n",
    "            self.embeddings = self._create_embeddings(\n",
    "                output_path=self.embeddings_path, \n",
    "                lines=lines\n",
    "            )\n",
    "            self.logger.info('Embeddings were successfully created.')\n",
    "\n",
    "    def _split_into_many(self, text: str, max_tokens: int = 500) -> List[str]:\n",
    "        ''' Function to split the text into chunks of a maximum number of tokens '''\n",
    "\n",
    "        # Split the text into sentences\n",
    "        sentences = text.split('. ')\n",
    "\n",
    "        # Get the number of tokens for each sentence\n",
    "        n_tokens = [len(self.tokenizer.encode(\" \" + sentence)) for sentence in sentences]\n",
    "        \n",
    "        chunks = []\n",
    "        tokens_so_far = 0\n",
    "        chunk = []\n",
    "\n",
    "        # Loop through the sentences and tokens joined together in a tuple\n",
    "        for sentence, token in zip(sentences, n_tokens):\n",
    "\n",
    "            # If the number of tokens so far plus the number of tokens in the current sentence is \n",
    "            # greater than the max number of tokens, then add the chunk to the list of chunks and \n",
    "            # reset the chunk and tokens so far\n",
    "            if tokens_so_far + token > max_tokens:\n",
    "                chunks.append(\". \".join(chunk) + \".\")\n",
    "                chunk = []\n",
    "                tokens_so_far = 0\n",
    "\n",
    "            # If the number of tokens in the current sentence is greater than the max number of \n",
    "            # tokens, go to the next sentence\n",
    "            if token > max_tokens:\n",
    "                continue\n",
    "\n",
    "            # Otherwise, add the sentence to the chunk and add the number of tokens to the total\n",
    "            chunk.append(sentence)\n",
    "            tokens_so_far += token + 1\n",
    "\n",
    "        return chunks\n",
    "        \n",
    "    def _shortened(self, kb_path, max_tokens: int = 500) -> List[str]:\n",
    "        ''' Ensures each kb article is shorter than max_tokens number of tokens. '''\n",
    "        shortened = []\n",
    "        with open(kb_path) as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                # If the text is None, go to the next row\n",
    "                if line is None:\n",
    "                    continue\n",
    "\n",
    "                # If the number of tokens is greater than the max number of tokens, split the text \n",
    "                # into chunks\n",
    "                if len(self.tokenizer.encode(line)) > max_tokens:\n",
    "                    shortened += self._split_into_many(line, max_tokens=max_tokens)\n",
    "                \n",
    "                # Otherwise, add the text to the list of shortened texts\n",
    "                else:\n",
    "                    shortened.append(line)\n",
    "        return shortened\n",
    "    \n",
    "    def _create_embeddings(self, output_path: Union[str, Path], lines: Sequence[str]) -> pd.DataFrame:\n",
    "        ''' Create embeddings for kb articles using OpenSi services. '''\n",
    "        df = pd.DataFrame(lines, columns = ['text'])\n",
    "        df['embeddings'] = df.text.apply(\n",
    "            lambda x: openai.Embedding.create(\n",
    "                input=x, \n",
    "                engine=self.embeddings_engine_name\n",
    "            )['data'][0]['embedding']\n",
    "        )\n",
    "        df['n_tokens'] = df.text.apply(\n",
    "            lambda x: len(self.tokenizer.encode(\" \" + x))\n",
    "        )\n",
    "        df.to_csv(output_path, index=False)\n",
    "        return df\n",
    "    \n",
    "    def create_context(self, question: str) -> str:\n",
    "        \"\"\"\n",
    "        Create a context for a question by finding the most similar context from the embeddings\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the embeddings for the question\n",
    "        q_embeddings = openai.Embedding.create(\n",
    "            input=question, \n",
    "            engine=self.embeddings_engine_name\n",
    "        )['data'][0]['embedding']\n",
    "        \n",
    "        df = self.embeddings\n",
    "        # Get the distances from the embeddings\n",
    "        df['distances'] = distances_from_embeddings(\n",
    "            q_embeddings, \n",
    "            df['embeddings'].values, \n",
    "            distance_metric='cosine'\n",
    "        )\n",
    "\n",
    "        returns = []\n",
    "        cur_len = 0\n",
    "\n",
    "        # Sort by distance and add the text to the context until the context is too long\n",
    "        for _, row in df.sort_values('distances', ascending=True).iterrows():\n",
    "            \n",
    "            # Add the length of the text to the current length\n",
    "            cur_len += row['n_tokens'] + 4\n",
    "            \n",
    "            # If the context is too long, break\n",
    "            if cur_len > self.max_prompt_len:\n",
    "                break\n",
    "            \n",
    "            # Else add it to the text that is being returned\n",
    "            returns.append(row[\"text\"])\n",
    "\n",
    "        # Return the context\n",
    "        return \"\\n\\n###\\n\\n\".join(returns)\n",
    "    \n",
    "    def answer_question(self, \n",
    "        question: str, \n",
    "        stop_sequence: Optional[str] = None,\n",
    "        temperature: float = 0.0,\n",
    "        debug=False\n",
    "    ) -> str:\n",
    "        \"\"\"Answer a question based on the most similar context from the kb.\"\"\"\n",
    "        context = self.create_context(question)\n",
    "        self.logger.debug(\"Context:\\n%s\", context)\n",
    "        if debug:\n",
    "            print(\"Context:\\n{}\".format(context))\n",
    "        prompt = self.PROMPT_TEMPLATES[self.kb_language].format(context=context, question=question)\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": prompt}\n",
    "        ]\n",
    "        messages += self.history\n",
    "        messages += [{\"role\": \"user\", \"content\": question}]\n",
    "\n",
    "        try:\n",
    "            # Create a completions using the question and context        \n",
    "            api_resp = openai.ChatCompletion.create(\n",
    "                messages=messages,\n",
    "                temperature=temperature,\n",
    "                stop=stop_sequence,\n",
    "                max_tokens=self.max_response_len,\n",
    "                top_p=1,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0,\n",
    "                model=self.model_name,\n",
    "            )\n",
    "            response = api_resp[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            self.history.append({\"role\": \"user\", \"content\": question})\n",
    "            self.history.append({\"role\": \"assistant\", \"content\": response})\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            self.logger.exception(e)\n",
    "            return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "openai_api_key = getpass.getpass('Enter OpenAI API key:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ChatBot('empatair', 'it', openai_api_key, max_prompt_len=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "Posso portare oggetti di valore a bordo? Sì, puoi portarli.\n",
      "\n",
      "###\n",
      "\n",
      "E se ho una borsa più piccola? Posso portare il mio zainetto a bordo? I passeggeri possono viaggiare con un bagaglio a mano gratuito.\n",
      "\n",
      "###\n",
      "\n",
      "Posso portare sia l'attrezzatura da sci sia quella per snowboard con me? No, è possibile portare solo un set di attrezzatura sportiva per passeggero per volo.\n",
      "\n",
      "###\n",
      "\n",
      "Viene garantito che l'attrezzatura sportiva viaggerà con me?\" No, purtroppo è previsto un limite per le attrezzature sportive per ciascun volo.\n",
      "\n",
      "###\n",
      "\n",
      "Posso portare l'attrezzatura da sci/snowboard con me? Sì, puoi portare la tua attrezzatura da sci/snowboard come bagaglio da stiva.\n",
      "\n",
      "###\n",
      "\n",
      "Posso usare il mio dispositivo per l'ossigeno durante il volo? No, il contenitore per l'ossigeno non può essere portato a bordo.\n",
      "\n",
      "###\n",
      "\n",
      "Sono cieco. Posso portare il mio cane con me? Sì, puoi portare gratuitamente il tuo cane guida.\n",
      "\n",
      "###\n",
      "\n",
      "Carrozzine e passeggini devono essere imbarcati con gli altri bagagli e verranno trasportati gratuitamente solo se l'utente dell'attrezzatura è un passeggero del volo.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Come ho detto in precedenza, dipende dalle politiche della compagnia aerea e dalle normative del paese di destinazione. In generale, alcune compagnie aeree consentono il trasporto di animali domestici, ma potrebbero essere previste restrizioni o costi aggiuntivi. Tuttavia, per quanto riguarda gli animali non domestici, come ad esempio animali esotici o selvatici, di solito non è consentito il loro trasporto sui voli commerciali. Ti consiglio di contattare direttamente la compagnia aerea per maggiori informazioni.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.answer_question(\"Si possono portare animali sui voli?\", debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Mi dispiace, non ho informazioni riguardo all'età di un contadino. Tuttavia, l'età di un contadino non è rilevante per i voli aerei.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.answer_question(\"Come si chiama ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d61f1220a9d67b3bf396d455a7c01af2e06045ad7a3f61245d91ccad865b361c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
